---
title: "The Power of Efficiency"
format: html
editor: visual
---

As we’ve said in the class efficiency is a pivotal component of statistical computing (and data science). In this essay, give an explanation of what that term “efficiency” means in relation to statistical computing and describe some places where you encountered efficiency and understood its importance. Your essay should address the following questions:

-   What is the definition of “efficiency”?

-   What does efficiency look like in statistical computing / data science?

-   What does efficiency allow you to do?

-   Why is efficiency important?

-   Where did you encounter efficiency, and what were some [“a-ha” moments](https://www.merriam-webster.com/dictionary/aha%20moment) you had about efficiency? (For the latter, tie each a-ha moment to an artifact in the portfolio.)

    Efficiency is the most optimal use of resources such as memory and time while preserving the function of the task. Efficient processes are those that are designed with a general use case in mind, produce a robust and practical output, and terminate immediately when errors are detected. From an ethical standpoint, computing power and data is not always cheap and being able to write efficient code that minimizes the amount of computing power necessary reduces the environmental impact which is often overlooked, especially if you're computing in the cloud.\
    \
    There are many different forms that efficiency can take within a data science context. The most common comment I left when doing peer reviews was whether the assignment of an object was necessary. Knowing when to store things as an object saves program memory since additional objects build up overtime and take up unnecessary space on your computer. A majority of these objects being saved were temporary results just for display, so not storing the output eliminates the need to call the object with the relevant output, and saves space in the environment. When working with smaller data sets, this is not an issue, but if working with a larger data set, the number of built up objects hogs the computing environment's memory, decreasing overall efficiency.\
    \
    Efficiency could also look like writing pipelines that use function calls appropriately, such as using a semi-join or anti-join to simultaneously filter information from two tables and join the information together. Likewise, writing functions that are designed for general common use cases or are vectorized to perform operations on entire columns reduce the lines of code needed and ensures these common operations can be executed at an optimal time complexity. Controlling the program flow with function stops triggered by failing test cases also demonstrates efficiency as it immediately highlights the issue to be debugged for the user, and doesn't waste compute by finishing the rest of the program, which may run into undefined behavior.\
    \
    Efficiency allows me to write organized and powerful code in a timely manner, due to how simple it is to add onto and test an efficient codebase. An example of efficient code that I am proud of is the function demonstrated in R3. Rather than writing an entirely new function to rescale the column values of a dataframe, I reused a vectorized function that I wrote previously. This function contained function stops which alerted me immediately if it has ran into an issue, and the fact that it was vectorized allowed me to process columns much faster than non vectorized functions. Because of this efficient code, I did not need to implement a new solution and was able to reuse an old algorithm which I already knew ran smoothly and quick enough for my purposes.
